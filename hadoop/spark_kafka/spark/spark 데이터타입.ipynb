{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adda2147-34de-4452-8f40-19c73bacbc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/spark'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80a3f5c-566a-4945-af98-b8468749e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = 'bydata/by-day/2010-12-01.csv'\n",
    "filepath = './bydata/by-day/2010-12-01.csv'   # /root/spark/bydata/by-day/2010-12-01.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba3a12f-1a3d-4334-9e2f-2409cda910d7",
   "metadata": {},
   "source": [
    "## 상대경로\n",
    "### 현재 위치에서 탐색  ./ : 현재경로 \n",
    "### ../  현재위치에서 한단계 위로 이동\n",
    "### ../../../  현재위치에서 3단계 위로 이동\n",
    "## 절대경로\n",
    "### 자신의 위치가 어디에 있는 전체 경로를 표시해서 탐색  / : 현재드라이버의 최 상단부터 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ea5bb1-b931-42cf-8682-4daf0d39ef4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read dataframe\n",
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(filepath)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c391639-0c63-4753-bbb7-ca6f7996f394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c49c374-c11e-46ad-a308-a0e2979e3bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e5718e2-f0e8-4d19-ba83-2c0181764d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "|  5|five|2.0|\n",
      "+---+----+---+\n",
      "|  5|five|2.0|\n",
      "|  5|five|2.0|\n",
      "+---+----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df.select(lit(5), lit('five'), lit(2.0)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0702c658-8013-4c37-a95c-e161cbdfcb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40a8f004-d576-414e-9768-6370fbbcd116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "\n",
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# InvoiceNo != 536365  InvoiceNo,Description만 출력하는데. 5개만\n",
    "spark.sql(\"\"\"\n",
    "    select InvoiceNo,Description from dfTable where InvoiceNo != 536365 limit 5\n",
    "\"\"\").show(truncate = False)\n",
    "\n",
    "df.where(col('InvoiceNo') != 536365).select('InvoiceNo','Description').show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b732be48-bac9-453a-816b-bdde00f97d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536544|      DOT|DOTCOM POSTAGE|       1|2010-12-01 14:32:00|   569.77|      NULL|United Kingdom|\n",
      "|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      NULL|United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1.UnitPrice 600 이상 \n",
    "# 2. Description POSTAGE 문자열이 포함\n",
    "# StockCode의 값중에 DOT 인 행을 선택 하는데  1번과 2번의 조건중에 하나라도 만족하면\n",
    "# spark.sql(\"\"\"\n",
    "\n",
    "# \"\"\").show()\n",
    "\n",
    "from pyspark.sql.functions import instr\n",
    "dotcondition = col('StockCode') == 'DOT'\n",
    "pricecondition = col('UnitPrice') > 600\n",
    "descondition = instr(col('Description'),'POSTAGE') >= 1\n",
    "# descondition = col('Description').isin('POSTAGE')\n",
    "\n",
    "df.where(dotcondition).where(pricecondition | descondition).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe3796f6-1e40-4e62-a875-5b06d73ae876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536544|      DOT|DOTCOM POSTAGE|       1|2010-12-01 14:32:00|   569.77|      NULL|United Kingdom|\n",
      "|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      NULL|United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select * from dfTable where StockCode = 'DOT' and (UnitPrice > 600 or  INSTR(Description,'POSTAGE') >= 1 )\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbbe2a4f-913d-43ef-a1eb-a965c4348d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|isExpensive|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|      false|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|      false|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 조건을 만들고 조건에 맞는 새로운데이터를 새로운 컬럼에 넣어서 추가\n",
    "df.withColumn('isExpensive',dotcondition & (  pricecondition | descondition)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5a1c86c-f616-4da7-b164-4923f5d896ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|UnitPrice|isExpensive|\n",
      "+---------+-----------+\n",
      "|   569.77|       true|\n",
      "|   607.49|       true|\n",
      "+---------+-----------+\n",
      "\n",
      "+---------+-----------+\n",
      "|UnitPrice|isExpensive|\n",
      "+---------+-----------+\n",
      "|   569.77|       true|\n",
      "|   607.49|       true|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# isExpensive True 인 항목중에 UnitPrice, isExpensive 출력\n",
    "df.withColumn('isExpensive',dotcondition & (  pricecondition | descondition))\\\n",
    ".where(col('isExpensive') == 'true')\\\n",
    ".select('UnitPrice','isExpensive').show(2)\n",
    "\n",
    "\n",
    "df.withColumn('isExpensive',dotcondition & (  pricecondition | descondition))\\\n",
    ".where('isExpensive == true')\\\n",
    ".select('UnitPrice','isExpensive').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed80b5e9-fa46-436c-b0c7-bd8d5287aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, pow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f23b5e3-551c-4648-b714-63f0d7b3e479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|     realQuantity'|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (수량*가격)**2 +5 --> 새로운 컬럼에 대입\n",
    "new_col = pow(col('Quantity')*col('UnitPrice'),2)+5\n",
    "df.select(expr('CustomerId'), new_col.alias(\"realQuantity'\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "478490a2-bfd5-432c-acda-ab271fbea1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round, bround, lit\n",
    "df.select(round(lit('2.5')), bround(lit('2.5'))).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aafb369b-df24-441e-b282-31e32c92270f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|         UnitPrice|\n",
      "+-------+------------------+\n",
      "|  count|              3108|\n",
      "|   mean| 4.151946589446603|\n",
      "| stddev|15.638659854603892|\n",
      "|    min|               0.0|\n",
      "|    max|            607.49|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('UnitPrice').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "99c252ce-fcdd-4860-bd8c-a2356aa993e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.51]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import count,mean,stddev_pop, min,max\n",
    "# stddev_pop : 표준편차.. 모집단의 표준편차 - 모든 개체에 대한 표준편차 즉.. 실제 표준 편차를 계산\n",
    "# stddev : 표본의 표준편차\n",
    "\n",
    "colname = 'UnitPrice'\n",
    "quantileProbs = [0.5]  # 사분위수 0.5 중위수를 나타냄\n",
    "realError = 0.05\n",
    "df.stat.approxQuantile(colname,quantileProbs,realError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a61b07aa-408d-49a7-b587-9dcf7cfa9e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+---+---+---+\n",
      "|StockCode_Quantity|  2| 32|  6|  8|\n",
      "+------------------+---+---+---+---+\n",
      "|            85123A|  0|  0|  1|  0|\n",
      "|             71053|  0|  0|  1|  0|\n",
      "|            84406B|  0|  0|  0|  1|\n",
      "|            84029G|  0|  0|  1|  0|\n",
      "|            84029E|  0|  0|  1|  0|\n",
      "|             22752|  1|  0|  0|  0|\n",
      "|             21730|  0|  0|  1|  0|\n",
      "|             22633|  0|  0|  1|  0|\n",
      "|             22632|  0|  0|  1|  0|\n",
      "|             84879|  0|  1|  0|  0|\n",
      "+------------------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df 데이터중에서  df_stockcode_quantity_top10  10개만 추출한 dataframe\n",
    "df_stockcode_quantity_top10 = df.limit(10)\n",
    "df_stockcode_quantity_top10.stat.crosstab(\"StockCode\",\"Quantity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3ddbcbf9-42bc-4a78-a0b4-6aab01069f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------+\n",
      "|StockCode_freqItems                                                       |\n",
      "+--------------------------------------------------------------------------+\n",
      "|[22752, 22632, 22633, 84879, 71053, 84406B, 85123A, 21730, 84029E, 84029G]|\n",
      "+--------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stockcode_quantity_top10.stat.freqItems([\"StockCode\"]).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e3a10d7d-2e6b-4e96-a5be-19d3c6711554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|StockCode|Quantity|\n",
      "+---------+--------+\n",
      "|   85123A|       6|\n",
      "|    71053|       6|\n",
      "|   84406B|       8|\n",
      "|   84029G|       6|\n",
      "|   84029E|       6|\n",
      "|    22752|       2|\n",
      "|    21730|       6|\n",
      "|    22633|       6|\n",
      "|    22632|       6|\n",
      "|    84879|      32|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stockcode_quantity_top10.select(\"StockCode\",\"Quantity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "479ce323-7014-4e68-87ef-6b27c5e13b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|monotonically_increasing_id()|\n",
      "+-----------------------------+\n",
      "|                            0|\n",
      "|                            1|\n",
      "|                            2|\n",
      "|                            3|\n",
      "|                            4|\n",
      "|                            5|\n",
      "|                            6|\n",
      "|                            7|\n",
      "|                            8|\n",
      "|                            9|\n",
      "|                           10|\n",
      "|                           11|\n",
      "|                           12|\n",
      "|                           13|\n",
      "|                           14|\n",
      "|                           15|\n",
      "|                           16|\n",
      "|                           17|\n",
      "|                           18|\n",
      "|                           19|\n",
      "+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "df.select(monotonically_increasing_id()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a43b209b-0df0-44a0-a4d8-355e1f7cfd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|initcap(Description)|\n",
      "+--------------------+\n",
      "|White Hanging Hea...|\n",
      "| White Metal Lantern|\n",
      "|Cream Cupid Heart...|\n",
      "|Knitted Union Fla...|\n",
      "|Red Woolly Hottie...|\n",
      "|Set 7 Babushka Ne...|\n",
      "|Glass Star Froste...|\n",
      "|Hand Warmer Union...|\n",
      "|Hand Warmer Red P...|\n",
      "|Assorted Colour B...|\n",
      "|Poppy's Playhouse...|\n",
      "|Poppy's Playhouse...|\n",
      "|Feltcraft Princes...|\n",
      "|Ivory Knitted Mug...|\n",
      "|Box Of 6 Assorted...|\n",
      "|Box Of Vintage Ji...|\n",
      "|Box Of Vintage Al...|\n",
      "|Home Building Blo...|\n",
      "|Love Building Blo...|\n",
      "|Recipe Box With M...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import initcap\n",
    "df.select(initcap(\"Description\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "20cba6cd-6b98-4338-bd26-658fd26c40e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|         Description|  lower(Description)|  lower(Description)|  upper(Description)|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|WHITE HANGING HEA...|white hanging hea...|white hanging hea...|WHITE HANGING HEA...|\n",
      "| WHITE METAL LANTERN| white metal lantern| white metal lantern| WHITE METAL LANTERN|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower,upper\n",
    "df.select(col('Description'),lower('Description'),lower('Description'),upper('Description')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "da4dc5a3-aede-4c9a-86c3-c2dff716acdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+----------------------------------+\n",
      "|Description                       |translate(Description, LEFT, 1234)|\n",
      "+----------------------------------+----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|WHI42 HANGING H2AR4 4-1IGH4 HO1D2R|\n",
      "|WHITE METAL LANTERN               |WHI42 M24A1 1AN42RN               |\n",
      "+----------------------------------+----------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import translate\n",
    "df.select('Description',translate(\"Description\", 'LEFT','1234')).show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "065efa6c-72f4-49e1-b8d9-76dfd2064b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|color|         Description|\n",
      "+-----+--------------------+\n",
      "|WHITE|WHITE HANGING HEA...|\n",
      "|WHITE| WHITE METAL LANTERN|\n",
      "|     |CREAM CUPID HEART...|\n",
      "|     |KNITTED UNION FLA...|\n",
      "|  RED|RED WOOLLY HOTTIE...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 정규표현식  Description 중에서 색상과 관련된 단어가 있는지 조사 \n",
    "from pyspark.sql.functions import regexp_extract\n",
    "extract_str =\"(BLACK|WHITE|RED|GREEN|BLUE)\"\n",
    "df.select(\n",
    "    regexp_extract('Description',extract_str,1).alias('color'),\n",
    "    'Description'\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "25196fa4-2d9b-41cf-800d-e50250d9a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|hasColorBW|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+----------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|      true|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|      true|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# instr 함수를 이용해서 df Description중에서 특정 문자열이 포함되어 있는지 여부를 확인하고 새로운 열을 추가\n",
    "# 'BLACK', 'WHITE'    --> hasColorBW\n",
    "containBlack =  instr('Description','BLACK') >=1\n",
    "containWhite =  instr('Description','WHITE') >=1\n",
    "df.withColumn('hasColorBW', containBlack|containWhite).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "04918e87-d366-4a6a-af0a-a97dd1245e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|Description                       |\n",
      "+----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|\n",
      "|WHITE METAL LANTERN               |\n",
      "|RED WOOLLY HOTTIE WHITE HEART.    |\n",
      "+----------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, locate\n",
    "simpleColors = [\"black\", \"white\", \"red\", \"green\", \"blue\"]\n",
    "def color_locator(column, color_string):\n",
    "  return locate(color_string.upper(), column)\\\n",
    "          .cast(\"boolean\")\\\n",
    "          .alias(\"is_\" + color_string)\n",
    "selectedColumns = [color_locator(df.Description, c) for c in simpleColors]\n",
    "selectedColumns.append(expr(\"*\")) # Column 타입이어야 합니다.\n",
    "\n",
    "# unpacking\n",
    "df.select(*selectedColumns).where(expr(\"is_white OR is_red\"))\\\n",
    "  .select(\"Description\").show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0bb1ef63-2899-4409-9a99-22b29db9b1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------------------+\n",
      "|id |today     |now                   |\n",
      "+---+----------+----------------------+\n",
      "|0  |2024-03-21|2024-03-21 14:08:00.69|\n",
      "|1  |2024-03-21|2024-03-21 14:08:00.69|\n",
      "|2  |2024-03-21|2024-03-21 14:08:00.69|\n",
      "|3  |2024-03-21|2024-03-21 14:08:00.69|\n",
      "|4  |2024-03-21|2024-03-21 14:08:00.69|\n",
      "|5  |2024-03-21|2024-03-21 14:08:00.69|\n",
      "|6  |2024-03-21|2024-03-21 14:08:00.69|\n",
      "|7  |2024-03-21|2024-03-21 14:08:00.69|\n",
      "|8  |2024-03-21|2024-03-21 14:08:00.69|\n",
      "|9  |2024-03-21|2024-03-21 14:08:00.69|\n",
      "+---+----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 날짜\n",
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "datedf = spark.range(10).withColumn('today',current_date())\\\n",
    "                .withColumn(\"now\",current_timestamp())\n",
    "datedf.show(truncate=False)\n",
    "datedf.createOrReplaceTempView('datedf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e1b2f025-4814-47e5-bac8-2f633a6ed378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_add, date_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "00749b20-44df-4e34-9ba1-2838fa374226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+\n",
      "|date_sub(today, 30)|date_add(today, 30)|\n",
      "+-------------------+-------------------+\n",
      "|         2024-02-20|         2024-04-20|\n",
      "+-------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datedf.select(date_sub('today',30), date_add('today',30)).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3152311f-627b-467b-a562-4caaad28bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|datediff(week_ago, today)|\n",
      "+-------------------------+\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "+-------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import datediff,months_between,to_date\n",
    "datedf.withColumn('week_ago',date_sub('today',7))\\\n",
    "        .select(datediff('week_ago','today')).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "020e09e5-d79a-429c-a5b2-fd28a6478fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|months_between(end, start, true)|\n",
      "+--------------------------------+\n",
      "|                      1.58064516|\n",
      "+--------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datedf.select(\n",
    "    to_date(lit('2024-03-21')).alias('start'),\n",
    "    to_date(lit('2024-05-08')).alias('end'))\\\n",
    "    .select(months_between('end','start')).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b2c4d3e6-6f69-4164-b656-78e9aa980be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|to_date(2024-05-02, yyyy-dd-MM)|\n",
      "+-------------------------------+\n",
      "|                     2024-02-05|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateformat = 'yyyy-dd-MM'\n",
    "spark.range(1).select(to_date(lit('2024-05-02'), dateformat) ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "aa52618c-a664-4e5e-8fdc-3619a61b2320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|      date|to_date(date)|\n",
      "+----------+-------------+\n",
      "|2024-05-02|   2024-05-02|\n",
      "+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, lit\n",
    "spark.range(1).withColumn('date',lit('2024-05-02')).select('date',to_date('date')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "868fb699-1798-4753-83ff-a46d7d30bbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|coalesce(Description, CustomerId)  |\n",
      "+-----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER |\n",
      "|WHITE METAL LANTERN                |\n",
      "|CREAM CUPID HEARTS COAT HANGER     |\n",
      "|KNITTED UNION FLAG HOT WATER BOTTLE|\n",
      "|RED WOOLLY HOTTIE WHITE HEART.     |\n",
      "|SET 7 BABUSHKA NESTING BOXES       |\n",
      "|GLASS STAR FROSTED T-LIGHT HOLDER  |\n",
      "|HAND WARMER UNION JACK             |\n",
      "|HAND WARMER RED POLKA DOT          |\n",
      "|ASSORTED COLOUR BIRD ORNAMENT      |\n",
      "|POPPY'S PLAYHOUSE BEDROOM          |\n",
      "|POPPY'S PLAYHOUSE KITCHEN          |\n",
      "|FELTCRAFT PRINCESS CHARLOTTE DOLL  |\n",
      "|IVORY KNITTED MUG COSY             |\n",
      "|BOX OF 6 ASSORTED COLOUR TEASPOONS |\n",
      "|BOX OF VINTAGE JIGSAW BLOCKS       |\n",
      "|BOX OF VINTAGE ALPHABET BLOCKS     |\n",
      "|HOME BUILDING BLOCK WORD           |\n",
      "|LOVE BUILDING BLOCK WORD           |\n",
      "|RECIPE BOX WITH METAL HEART        |\n",
      "+-----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce\n",
    "df.select(coalesce('Description','CustomerId')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9f5a363c-d55c-44c3-9e24-19542b42dfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|   a|   b|\n",
      "+----+----+\n",
      "|NULL|   2|\n",
      "|   1|NULL|\n",
      "|   1|   2|\n",
      "|NULL|NULL|\n",
      "+----+----+\n",
      "\n",
      "+--------------+\n",
      "|coalesce(a, b)|\n",
      "+--------------+\n",
      "|2             |\n",
      "|1             |\n",
      "|1             |\n",
      "|NULL          |\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (None,2),\n",
    "    (1,None),\n",
    "    (1,2),\n",
    "    (None,None),\n",
    "]\n",
    "example_df = spark.createDataFrame(data,['a','b'])\n",
    "example_df.show()\n",
    "example_df.select(coalesce('a','b')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "30a2872d-b064-403b-8901-611c6da1a93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# StockCode, InvoiceNo가  NA 인 항목만 추출\n",
    "# df.filter( \"StockCode == 'None' or InvoiceNo == 'None'\").show()\n",
    "df.filter( col(\"StockCode\").isNull() | col(\"InvoiceNo\").isNull() ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e9a15b2d-5395-4c27-a8a6-365c7603d9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|   a|   b|\n",
      "+----+----+\n",
      "|NULL|   2|\n",
      "|   1|NULL|\n",
      "|NULL|NULL|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_df.filter(col('a').isNull() | col('b').isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9b690d8b-6783-4dc7-8b7f-4da964b63aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|  a|   b|\n",
      "+---+----+\n",
      "|  1|NULL|\n",
      "|  1|   2|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_df.na.drop('all', subset=['a']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b7111b56-573a-454c-8412-994b2ba42e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|   a|   b|\n",
      "+----+----+\n",
      "|NULL|   2|\n",
      "|   1|NULL|\n",
      "|   1|   2|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_df.na.drop('all', subset=['a','b']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "15cb3bc7-c5d4-4cd8-a8a2-e3847bde4ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|   a|   b|\n",
      "+----+----+\n",
      "|NULL|   2|\n",
      "|   1|NULL|\n",
      "|   1|   2|\n",
      "|NULL|NULL|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_df.na.fill('all', subset=['a','b']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a19b0b47-052f-4387-8dcb-730944b467b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  a|  b|\n",
      "+---+---+\n",
      "|100|  2|\n",
      "|  1|  5|\n",
      "|  1|  2|\n",
      "|100|  5|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fill_cols_vals = {'a':100,'b':5}\n",
    "example_df.na.fill(fill_cols_vals).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "38aafc80-d58a-41d9-b8c4-040bea52f72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|complete                                     |\n",
      "+---------------------------------------------+\n",
      "|{WHITE HANGING HEART T-LIGHT HOLDER, 536365} |\n",
      "|{WHITE METAL LANTERN, 536365}                |\n",
      "|{CREAM CUPID HEARTS COAT HANGER, 536365}     |\n",
      "|{KNITTED UNION FLAG HOT WATER BOTTLE, 536365}|\n",
      "|{RED WOOLLY HOTTIE WHITE HEART., 536365}     |\n",
      "|{SET 7 BABUSHKA NESTING BOXES, 536365}       |\n",
      "|{GLASS STAR FROSTED T-LIGHT HOLDER, 536365}  |\n",
      "|{HAND WARMER UNION JACK, 536366}             |\n",
      "|{HAND WARMER RED POLKA DOT, 536366}          |\n",
      "|{ASSORTED COLOUR BIRD ORNAMENT, 536367}      |\n",
      "|{POPPY'S PLAYHOUSE BEDROOM , 536367}         |\n",
      "|{POPPY'S PLAYHOUSE KITCHEN, 536367}          |\n",
      "|{FELTCRAFT PRINCESS CHARLOTTE DOLL, 536367}  |\n",
      "|{IVORY KNITTED MUG COSY , 536367}            |\n",
      "|{BOX OF 6 ASSORTED COLOUR TEASPOONS, 536367} |\n",
      "|{BOX OF VINTAGE JIGSAW BLOCKS , 536367}      |\n",
      "|{BOX OF VINTAGE ALPHABET BLOCKS, 536367}     |\n",
      "|{HOME BUILDING BLOCK WORD, 536367}           |\n",
      "|{LOVE BUILDING BLOCK WORD, 536367}           |\n",
      "|{RECIPE BOX WITH METAL HEART, 536367}        |\n",
      "+---------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 컬럼끼리 묶기 - 복합컬럼\n",
    "from pyspark.sql.functions import struct\n",
    "df.select( struct('Description','InvoiceNo').alias('complete')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "96f86076-78a7-4f04-abe7-282462752916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|split(Description,  , -1)               |\n",
      "+----------------------------------------+\n",
      "|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|\n",
      "|[WHITE, METAL, LANTERN]                 |\n",
      "+----------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "df.select(split(\"Description\", \" \")).show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "91ed5b6d-a49a-4389-a559-0c0dca5a890e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|array_col[0]|\n",
      "+------------+\n",
      "|       WHITE|\n",
      "|       WHITE|\n",
      "+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split(\"Description\", \" \").alias('array_col'))\\\n",
    "    .selectExpr('array_col[0]').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a4a4bcd3-be9c-4640-b2e6-dff64a67c59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|array_size|\n",
      "+----------+\n",
      "|         5|\n",
      "|         3|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import size\n",
    "df.select( size(split(\"Description\", \" \")).alias('array_size')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1ef12130-69eb-4a15-8a82-2b467971d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|Description                       |\n",
      "+----------------------------------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|\n",
      "|WHITE METAL LANTERN               |\n",
      "+----------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Description').show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "597d64d4-1938-42d6-91c1-5df5e1c5e1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+----------------------------------------+--------+\n",
      "|Description                       |splitted                                |exploded|\n",
      "+----------------------------------+----------------------------------------+--------+\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|WHITE   |\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|HANGING |\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|HEART   |\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|T-LIGHT |\n",
      "|WHITE HANGING HEART T-LIGHT HOLDER|[WHITE, HANGING, HEART, T-LIGHT, HOLDER]|HOLDER  |\n",
      "|WHITE METAL LANTERN               |[WHITE, METAL, LANTERN]                 |WHITE   |\n",
      "|WHITE METAL LANTERN               |[WHITE, METAL, LANTERN]                 |METAL   |\n",
      "+----------------------------------+----------------------------------------+--------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 새로운 행으로 확장 explode\n",
    "from pyspark.sql.functions import explode, split\n",
    "df.withColumn('splitted',split(\"Description\", \" \"))\\\n",
    "    .withColumn('exploded',explode('splitted'))\\\n",
    "    .select('Description','splitted','exploded').show(7,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8a2e20cd-d4d4-48f7-9a13-e006ef9e09a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+\n",
      "|complex_ma                                    |\n",
      "+----------------------------------------------+\n",
      "|{WHITE HANGING HEART T-LIGHT HOLDER -> 536365}|\n",
      "|{WHITE METAL LANTERN -> 536365}               |\n",
      "+----------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from  pyspark.sql.functions import create_map\n",
    "df.select(create_map('Description','InvoiceNo').alias('complex_ma')).show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "dd84d4e3-b1a5-4f41-8471-68b13a4ecf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|complex_map[WHITE METAL LANTERN]|\n",
      "+--------------------------------+\n",
      "|                            NULL|\n",
      "|                          536365|\n",
      "+--------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(create_map('Description','InvoiceNo').alias('complex_map'))\\\n",
    "    .selectExpr('complex_map[\"WHITE METAL LANTERN\"]').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "12775c9e-9f65-49c2-98c2-e7cfdc45eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json type DataFrame\n",
    "json_df = spark.range(1).selectExpr(\"\"\"\n",
    "    '{\"myJSONKey\" : {\"myJSONValue\" : [1,2,3]}}' as jsonString\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f1416c6e-8b4d-4cd7-a564-080151a440b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|jsonString                               |\n",
      "+-----------------------------------------+\n",
      "|{\"myJSONKey\" : {\"myJSONValue\" : [1,2,3]}}|\n",
      "+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9e60b5e2-e565-4087-b921-394dfcedd71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------+\n",
      "|column|c0                     |\n",
      "+------+-----------------------+\n",
      "|2     |{\"myJSONValue\":[1,2,3]}|\n",
      "+------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import get_json_object, json_tuple\n",
    "json_df.select(\n",
    "    get_json_object('jsonString', \"$.myJSONKey.myJSONValue[1]\").alias('column'),\n",
    "    json_tuple('jsonString','myJSONKey')\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "38dd0865-2e85-4ec6-b3ac-2c0443cb1052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|myStruct                                    |\n",
      "+--------------------------------------------+\n",
      "|{536365, WHITE HANGING HEART T-LIGHT HOLDER}|\n",
      "|{536365, WHITE METAL LANTERN}               |\n",
      "+--------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_json\n",
    "df.selectExpr(\"(InvoiceNo, Description) as myStruct\").show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "210b2ff9-5c3a-49a4-b8a0-5034ea9c28c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+\n",
      "|to_json(myStruct)                                                        |\n",
      "+-------------------------------------------------------------------------+\n",
      "|{\"InvoiceNo\":\"536365\",\"Description\":\"WHITE HANGING HEART T-LIGHT HOLDER\"}|\n",
      "|{\"InvoiceNo\":\"536365\",\"Description\":\"WHITE METAL LANTERN\"}               |\n",
      "+-------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"(InvoiceNo, Description) as myStruct\")\\\n",
    ".select(to_json('myStruct'))\\\n",
    ".show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b63928-7d2f-4e97-a7b6-1e0b0c589754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
